#!/usr/bin/env python3
"""
Teste com modelo menor para comparar performance
"""
import requests
import time

def test_with_smaller_model():
    url = "http://localhost:5000/v1/chat/completions"
    
    payload = {
        "model": "llama3.2:3b",  # Modelo menor
        "messages": [
            {
                "role": "user", 
                "content": "O que √© diversifica√ß√£o de investimentos? Resposta breve."
            }
        ],
        "temperature": 0.7,
        "max_tokens": 150
    }
    
    print("üß™ Testando com modelo menor (llama3.2:3b)...")
    
    start_time = time.time()
    
    try:
        response = requests.post(url, json=payload, timeout=120)
        end_time = time.time()
        
        response_time = end_time - start_time
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            print(f"‚úÖ Sucesso! Tempo: {response_time:.2f}s")
            print(f"üìù Resposta: {content}")
            
            if response_time < 20:
                print("üöÄ Muito r√°pido! < 20s")
            elif response_time < 40:
                print("‚úÖ R√°pido! < 40s")
            elif response_time < 60:
                print("üî∂ OK! < 1 minuto")
            else:
                print("‚ùå Ainda lento > 1 minuto")
                
        else:
            print(f"‚ùå Erro HTTP {response.status_code}: {response.text}")
            
    except Exception as e:
        print(f"‚ùå Erro: {e}")

if __name__ == "__main__":
    test_with_smaller_model()
